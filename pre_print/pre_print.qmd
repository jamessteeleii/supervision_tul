---
articletitle: |
  The effects of supervision upon effort during resistance training: A Bayesian analysis of prior data and an experimental study of private strength clinic members
# shorttitle: "Doe et al. (2022)" # usually auto-generated
format: 
  sportrxiv-pdf:
    include-in-header:
      text: |
       \usepackage[font=scriptsize]{caption}
       \usepackage{caption}
author:
  - name: James Steele
    affiliations:
      - ref: 1
      - ref: 2
      - ref: 3
    orcid: 0000-0002-8003-0757
    corresponding: true
    email: james@steele-research.com
  - name: James Fisher
    affiliations:
      - ref: 3
    orcid: 0000-0002-6013-8402
    email: james.fisher.phd@outlook.com
  - name: Tim Dettmann
    affiliations:
      - ref: 1
    email: tim.dettmann@gmail.com
affiliations:
      - id: 1
        name: Kieser Australia, Melbourne, Australia
      - id: 2
        name: Steele Research Limited, Eastleigh, UK
      - id: 3
        name: Department of Sport and Health, Solent University, Southampton, UK
      - id: 4
        name: The Exercise Coach, Tennessee, USA
abstract: |
  Recent work has suggested that supervision during resistance training might enhance outcomes such as strength adaptation due to role that it plays in optimising trainee effort. We were afforded an opportunity to examine the role of supervision on effort during resistance training in a unique setting with several private strength clinics whose members train either unsupervised on a "Core" membership or supervised by a qualified exercise scientist on an "Assisted" membership. Both retrospectively through examination of samples of member training records, and through a prospective experimental study, we examined the effects of supervision upon exercise performance as time under load (TUL), rating of perceived effort (RPE), and rating of perceived discomfort. We adopted Bayesian methods for modelling and from the prior sample of retrospective data generated empirically informed posterior distributions to use as prior distributions in our modelling of the experimental study. The prior sample consisted of training sessions from 1000 each of Core and Assisted members, whilst the experimental study consisted of Core members recruited to in randomised order complete an unsupervised and a supervised session using their current training loads where they were instructed to perform each exercise to momentary failure. Our findings suggest that, *in situ* under real world settings (i.e., our prior sample of members) there was little difference in exercise performance, yet in our experimental study there was a clear benefit to TUL performance when under supervision (Core = 125.12 [95%QI: 113.70, 131.90] seconds; Assisted = 147.35 [95%QI: 134.29, 154.81] seconds; Core minus Assisted contrast = -22.10 [95%QI: -26.60, -17.61] seconds). There was a small difference in RPE in percentage points reported with and without supervision under both real world (Core = 53% [95%QI: 51%, 55%]; Assisted = 59% [95%QI: 57%, 61%]; Core minus Assisted contrast = -6% [95%QI: -8%, -4%]) and experimental conditions (Core = 81% [95%QI: 75%, 86%]; Assisted = 87% [95%QI: 83%, 91%]; Core minus Assisted contrast = -6% [95%QI: -10%, -4%]) suggesting a that under supervision trainees train with greater proximity to failure, which was also supported by greater rating of perceived discomfort under supervision during the experimental study (Core = 6.3 [95%QI: 5.1, 7.3] pts; Assisted = 7.5 [95%QI: 6.5, 8.3] pts; Core minus Assisted contrast = -1.2 [95%QI: -1.6, -0.9] pts). These results in general support prior work highlighting the importance of supervision during RT and that under unsupervised, and perhaps more so during real world conditions, trainees likely train with suboptimal effort.
license-type: ccby # change if neccessary
# year: 2025 # defaults to current year
keywords: [template, demo, exercise science] # optional
# optional link to Supplementary Material:
suppl-link: https://osf.io/ 
reference-section-title: References
printnote: "PREPRINT - NOT PEER REVIEWED" # if post print, include "POSTPRINT" then link to the published article
bibliography: bibliography.bib  
pdf-engine: xelatex
execute: 
  echo: false
  message: false
  warning: false
---

```{r}
library(patchwork)
library(tidyverse)
library(marginaleffects)
library(ggdist)

targets::tar_config_set(store = here::here('_targets'))

# posterior predict functions for hurdle model
posterior_predict_hurdle_student_t <- function(i, prep, ...) {
  nu <- brms::get_dpar(prep, "nu", i = i)
  mu <- brms::get_dpar(prep, "mu", i = i)
  sigma <- brms::get_dpar(prep, "sigma", i = i)
  theta <- brms::get_dpar(prep, "hu", i = i)
  
  hu <- runif(prep$ndraws, 0, 1)
  ifelse(hu < theta, 0, brms::rstudent_t(prep$ndraws, nu, mu, sigma))
}


posterior_epred_hurdle_student_t <- function(prep) {
  with(prep$dpars, mu * (1 - hu))
}
```

# Introduction

Recent work has highlighted the importance of supervision in optimising strength outcomes from resistance training (RT). In a recent systematic review and meta-analysis from Fisher et al. [-@fisherRoleSupervisionResistance2022a] there was a moderate standardised mean effect (0.40 \[95%CI: 0.06, 0.74\]) of supervised vs unsupervised RT on strength outcomes synthesised from ten studies. Since then, a further study has reported that even in previously trained participants there may be benefit to strength outcomes from supervision [@colemanSupervisionResistanceTraining2023].

It has been speculated [@fisherRoleSupervisionResistance2022a] that an explanation for this effect may be due to the role that a trainer plays in prescribing load progression for the trainee, whereas when there is no clear load progression rule unsupervised trainees may be less likely to train with appropriate loads, and ultimately appropriate effort. Indeed, a recent meta-analysis examining the relative loads selected by trainees when given the ability to self-select highlights that they tend to choose loads which, whilst initially efficacious in novice trainees, become sub-optimal quickly as training experience progresses (\~53% of one repetition maximum \[1RM\]) particularly when combined with the typical repetition ranges prescribed i.e., \~8 to 15 repetitions [@steeleAreTraineesLifting2022]. Further, when given the opportunity to self-select load and the number of repetitions to complete there is evidence that trainees likely train with relatively low effort as determined from their proximity to momentary failure i.e., \~10 repetitions at \~53% 1RM [@steeleAreTraineesLifting2022; @nuzzoMaximalNumberRepetitions2024]. Thus, whether self-selecting a load for a typically prescribed repetition range or self-selecting a load and self-selecting the number of repetitions to perform, most will perform sets with an estimated proximity of \~10-20 repetitions shy of momentary failure.

As such it has also been suggested that a supervising trainer plays the role of providing motivation and enhancing trainee effort [@fisherRoleSupervisionResistance2022a]. Indeed, recent survey studies highlight that trainees perceive supervision to have an important role in determining their motivation and resultant effort during RT which they also perceive to be important to achieve their training goals [@fisherSupervisionResistanceTraining2023; @carlsonMaleFemalePerceptions2024].

However, a recent meta-analysis of the dose-response relationship of proximity to momentary failure for strength and hypertrophy outcomes highlights that, while there is increased hypertrophy with closer proximity to failure, there is not a clear relationship for strength [@robinsonExploringDoseResponse2024]. But a caveat is that there was limited data for proximities to failure \>10 repetitions, and that the models were adjusted for load (average loads were typically \~75-85% of one repetition maximum). Thus, the results of this meta-analysis apply to proximity to failure *after* selecting load (i.e., intraset effort) and a higher relative load requires a greater effort all else being equal. When considering the average self-selected load of \~53% 1RM coupled with a typical \~10 repetitions per set equating to proximities to failure \>10 repetitions [@steeleAreTraineesLifting2022] it seems plausible that unsupervised trainees may train with a less-than-optimal load, repetitions, and resultant effort to optimise strength outcomes. Ultimately, and in combination, supervision should provide trainees with feedback of their past performance, whether technical, effort- or program-based, and guidance toward their future performance (Fisher, under review).

We were afforded an opportunity to examine the role of supervision on effort during RT in a unique setting with several private strength clinics whose members train either unsupervised on a "Core" membership[^1] or supervised by an exercise scientist on an "Assisted" membership both retrospectively and through a prospective experimental study. As such, using Bayesian methods, we examined samples of historical data from both types of client and in a sample of current Core members in which we investigated experimentally the impact of supervision from a qualified exercise scientist.

[^1]: Note, Core members do have a "Review" session every twentieth session with an exercise scientist to complete strength testing, and review their training programme cards including selection of exercises and weights.

# Methods

```{r}
targets::tar_load(data)
targets::tar_load(prior_data_tul)
targets::tar_load(prior_data_rpe)

```

## Experimental approach to the problem

The study was conducted at a selection of strength clinics operated by Kieser Australia recruiting from the existing pool of Core members at these locations. All Kieser Australia members are prescribed the same protocol. This consists of a single set of the resistance machine exercises prescribed on their current training programme card using a load that should permit them to reach momentary failure within a time-under-load of 90-120 seconds (though an upper limit of ~180 seconds TUL is enforced to avoid machines being occupied for too long on the clinic floor preventing other members from using them) using a \~ 10 seconds repetition duration (i.e., \~4:4 seconds concentric:eccentric actions with a 1 isometric second hold whilst still under load with tension on the involved musculature at the end of each concentric and eccentric muscle action). Core trainees are prompted to progress load by \~5% for the next session once a time-under-load of \>120 seconds is achieved for a particular exercise before reaching momentary failure, and for Assisted trainees this is actioned by their supervising Exercise Scientist . Trainees are prompted to complete a session rating of perceived effort (RPE) at the end of their training session. An acute randomised cross-over design was employed to examine participants completing an RT session with and without direct supervision with one week apart (i.e., a Core vs Assisted session). Participants were instructed to complete a single set of the resistance machine exercises on their current training programme card using their current training loads to momentary failure. The time under load (TUL) performed, and perceptions of effort and discomfort were recorded and compared between both conditions. This study was not pre-registered and as described below the sample size was justified based on logistical concerns and the analysis is considered exploratory. 

In addition to the experimental study design noted above, we also took samples of Core and Assisted trainees from historical data records in Kieser Australia's database. We took separate random samples to obtain both TUL and session RPE data. There were two reasons for this. Firstly, we used this data to generate empirical informative prior distributions to use in our Bayesian modelling of the experimental study data. Secondly, they allowed us to also explore in the descriptive[^2] difference between Core and Assisted training *in situ*, but also that we could compare the prior distribution for the random sample of Core members *in situ* with the posterior distribution of Core members completing their Core session in the experimental study to understand the extent to which study effects might influence outcomes.

The experimental study component of this project was approved by the Southampton Solent University Health Exercise and Sport Science Ethics committee (id: STEELEAUG2016). All participants provided informed consent to participate in the study. Data in the prior sample was used in de-identified form and with member consent for data to be used for research purposes. 

[^2]: Note that we do not claim this difference to be a causal effect in this data given that we have not adjusted for confounders, for example that different types of people might self-select into either Core or Assisted memberships and that this might confound comparisons of either TUL or session RPE.

## Participants

### Experimental

The study was advertised at five Kieser Australia strength clinics and we sought to recruit members who had \> 6 months prior training experience at the strength clinics, were healthy (no clinical conditions on their member record as recorded by a physiotherapist or exercise physiologist), both males and females (age +18 years), and without any current condition for which RT would be contraindicated. They were recruited from the existing client pool of Core members. We recruited a sample size based on considerations of what was logistically feasible given the availability of the exercise scientist staff at each clinic to conduct data collection and perform the supervised Assisted sessions and wanting to minimise the burden on day-to-day operation of the clinics. As such it was decided that a target of 50 participants across clinics would be acceptable. We ended up with n = `r length(unique(data$id))` participants recruited across the five clinics.

### Prior Sample

We queried the Kieser Australia database to generate random samples from historical data. We opted to generate reasonably large samples to ensure precise prior estimates, though did not use the entirety of the historical data (\~50000 members, \>10 years of data) so as to reduce computation time for Bayesian modelling. For TUL we limited data to Core and Assisted members training sessions that either were not led by an exercise scientist or were respectively[^3], took the first training session after at least 6 months of prior training at Kieser Australia had been completed by each member, randomly sampled 1000 Core and 1000 Assisted members and then filtered to the resistance machines used in by members in the experimental study so that we had a selection of members across varied clinic locations and completing sessions with a selection of resistance machine exercises and had TUL data for each exercise. Thus we ended up with a sample of n = `r length(unique(prior_data_tul$id))` (Core = `r length(unique(filter(prior_data_tul, core_assisted == "core")$id))`, Assisted = `r length(unique(filter(prior_data_tul, core_assisted == "assisted")$id))`). For session RPE we performed a similar database query and randomly sampled 1000 Core and 1000 Assisted members who had reported session RPE values.

[^3]: Whilst clients can have Core or Assisted memberships the former also have sessions that are supervised (i.e., their "Review" sessions noted in footnote$^1$) and the latter can have unsupervised sessions (i.e., they can attend the clinic outside of their scheduled sessions with the exercise scientist and train unsupervised). Thus we limited our sample to only normal training sessions which had been either unsupervised or supervised for both Core and Assisted members respectively.

## Protocols

All RT was performed using resistance machines (Kieser Training AG, Zurich, Switzerland) including the A1 (hip extension), A2 (torso flexion), A3 (hip abduction), B1 (leg extension), B6 (leg press), B7 (seated leg curl), C3 (torso arm i.e., pulldown), C7 (seated row), D5 (arm cross i.e., pectoral fly), D6 (chest press), D7 (seated dip), F2/F2.1 (abdominal flexion), and K2 (supported supinated grip pullup). For the experimental study participants were instructed to attend two training sessions at least one-week apart where they completed either their current Core session (i.e., unsupervised) or an Assisted session (i.e., supervised). During the Core session the participant completed their training session as prescribed with the only difference for the Assisted session being that an exercise scientist supervised them providing instruction and motivation, however, they did not interfere in any physical way during the set (e.g. to spot or assist in completing a failing repetition). Each participant had an existing training programme card. In both conditions they utilised the current training loads for each machine that were recorded in the last session of their training programme card prior to participation in the study. Participants were instructed to ensure that they continue performing the exercise to momentary failure independently of the time-under-load achieved for the purposes of the study i.e., if they realised during the set that their prior load selection was evidently too low for the prescribed TUL range they should continue to momentary failure regardless off the TUL. Momentary failure was defined as per Steele et al. [-@steeleClarityReportingTerminology2017] i.e., the point at which, despite their greatest effort, participants are unable to continue concentrically contracting and moving the resistance, and this was communicated to the participants. During each session for each exercise the trainees/trainers recorded their time-under-load achieved as they would do for their usual sessions using timers situated around the clinic in view during training specifically for this purpose. In addition, they recorded their perceptions of effort and discomfort in that order immediately upon completing the exercise using previously validated scales for differentiating these perceptions [@steeleDifferentiationPerceivedEffort2017]; scripts and scales are available here: [https://osf.io/ufvy8/](https://osf.io/ufvy8/).

The data generated from the sample of historical members was generated according to the standard protocol described above that all Kieser Australia members are prescribed. TUL was also recorded similarly using timers available about the clinic, r for some sessions using a more recently developed mobile phone application (Kieser Konnect, Kieser Australia) which has placed on a stand on the resistance machines and used to track TUL for each exercise in their training card which is programmed to the application. Session RPE was recorded using either the mobile application for Core members, or via the application used by staff during Assisted sessions and used a modified version of the Borg 6-20 scale with (where the scale is displayed as scrollable and the verbal anchors are "6 - None", "7- Very, very light", "13 – Somewhat hard", "19 - Very, very hard", and "20 – Maximal Exertion"
)

## Statistical Analysis

```         
    JAMES TO UPDATE LINKS/CITATION IN PARAGRAPH BELOW!!!!!!!!
```

All code utilised for data preparation and analyses are available in either the Open Science Framework page for this project <https://osf.io/dqwh5/> or the corresponding GitHub repository <https://github.com/jamessteeleii/self_talk_meta_analysis_update>. We cite all software and packages used in the analysis pipeline using the `grateful` package [@rodriguez-sanchezGratefulFacilitateCitation2023] which can be seen here: <https://osf.io/ftajc>.

As noted, the project was not pre-registered but involved exploratory analysis of the experimental and prior datasets. All analyses have been conducted within a Bayesian framework and all posterior estimates and their precision, along with conclusions based upon them, are interpreted continuously and probabilistically, considering priors, data quality, and all within the context of each outcome and the assumptions of the model employed as the estimator [@kruschkeBayesianNewStatistics2018]. All models were run with 2000 warmup and 2000 sampling iterations and four Monte Carlo Markov Chains. Trace plots were produced along with $\hat{R}$ values to examine whether chains had converged, and posterior predictive checks for each model were also examined to understand the model implied distributions. We fit two sets of models for the TUL and RPE outcomes, one on the prior sample of data using weakly regularising priors in order to generate posterior distributions to inform the priors used in the other model using the experimental data, and a single model on the experimental data for the rating of perceived discomfort outcome using weakly regularising priors. These models are described below. For all models we calculated average marginal effects as the global grand means for both predictions under each condition as well as contrasts between conditions and visualise both prior and posterior distributions along with median and 95% quantile interval (QI) estimates from these. 

### Time Under Load Analysis

Upon inspecting the raw distribution of the prior sample of data for TUL we noticed that there was a spike at 120 seconds concomitant with the top of the target TUL range prescribed to members under both Core and Assisted conditions (see @fig-raw). Anecdotal reports from Kieser Australia staff had also prior to exploring the data suggested to us that, despite the prescription to train to momentary failure, many Core members were instead selecting loads and training only to the upper 120 second TUL range threshold irrespective of proximity to failure. We did not however expect this to be the same for the prior sample of Assisted members. As such, it suggested to us that there might be two processes underlying the observed data: a tendency to target a specific TUL threshold and to stop the exercise at that point, or to otherwise continue the exercise to momentary failure (or to stop the exercise based on some other process such as tolerable proximity to failure). Thus, we opted to use a hurdle type model comprising a Bernoulli distribution for the probability of having a TUL of 120 seconds, and a student $t$ distribution for all other values of TUL[^4]. We expected this may also be the case in our experimental dataset given we recruited Core members and so utilised the same type of model for this. As such this allowed us to examine both the expectations of the global grand mean for TUL, in addition to the probabilities of having a TUL of 120 seconds. 

[^4]: A custom family for the hurdle-student $t$ model was produced for use with the `brms` R package, adapted from the hurdle-normal distribution developed by Heiss [-@heissGuideModelingOutcomes].

For both the prior sample and experimental study data the following model was employed which included a fixed (i.e., population level) effect for the session type, Core or Assisted, where Assisted was coded as the intercept. The model also included random (i.e., cluster or group level) effects as intercepts for the location (i.e., the clinic the session was performed at), the member id, and the resistance machine used (note, due to the cross-over nature of the experimental design the random effects for location, member, and machine were modelled as nested in this dataset). These fixed and random effects were modelled as predictors for both the hurdle and student $t$ components of the model. TUL was centred at zero for modelling (i.e., all values of TUL$_i$ has 120 subtracted from them prior to modelling). Formally the model(s) for $i^{th}$ TUL across condition $c$ within the $j^{th}$ location, $k^{th}$ member, $l^{th}$ machine were as follows:

$$
\tiny
\begin{aligned}
\text{TUL}_{ic} &\sim \operatorname{Hurdle\,log-student}t(\pi_{ic_{j[i],k[i],l[i]}}, \nu_y, \mu_{ic_{j[i],k[i],l[i]}}, \sigma_y) \ ...\ \text{or alternatively,} \\
\text{TUL}_{ic} &\sim
\begin{Bmatrix}
0 & \text{with probability } \pi_{ic_{j[i],k[i],l[i]}} \\[4pt]
\operatorname{Student}t(\mu_{ic_{j[i],k[i],l[i]}}, \nu_y, \sigma_y) & \text{with probability } 1 - \pi_{ic_{j[i],k[i],l[i]}}
\end{Bmatrix}
\\
\\
& \textbf{Models for distribution parameters} \\
\operatorname{logit}(\pi_{ic}) &= (\gamma_0 + \gamma_{0_{j[i],k[i],l[i]}}) + \gamma_1 \text{Condition}_{ic} & \text{120 seconds/not-120 seconds process} \\[4pt]
\mu_{ic} &= (\beta_0 + b_{0_{j[i],k[i],l[i]}}) + \beta_1\text{Condition}_{ic} & \text{Location parameter in student}\ t\ \text{process} \\[4pt]
\gamma_{0_j} &\sim \mathcal{N}(0, \sigma_{\gamma_{0_{j}}}), \text{for location j} = 1,\ ...,\text{J} & \text{Variation in intercepts for location in hurdle model} \\[4pt]
\gamma_{0_k} &\sim \mathcal{N}(0, \sigma_{\gamma_{0_{k}}}), \text{for member k} = 1,\ ...,\text{K} & \text{Variation in intercepts for member in hurdle model} \\[4pt]
\gamma_{0_l}, &\sim \mathcal{N}(0, \sigma_{\gamma_{0_{l}}}), \text{for machine l} = 1,\ ...,\text{L} & \text{Variation in intercepts for machine  in hurdle model} \\[4pt]
b_{0_j} &\sim \mathcal{N}(0, \sigma_{b_{0_{j}}}), \text{for location j} = 1,\ ...,\text{J} & \text{Variation in intercepts for location in student}\ t\ \text{model model} \\[4pt]
b_{0_k} &\sim \mathcal{N}(0, \sigma_{b_{0_{k}}}), \text{for member k} = 1,\ ...,\text{K} & \text{Variation in intercepts for member in student}\ t\ \text{model model} \\[4pt]
b_{0_l} &\sim \mathcal{N}(0, \sigma_{b_{0_{l}}}), \text{for machine l} = 1,\ ...,\text{L} & \text{Variation in intercepts for machine  in student}\ t\ \text{model model} \\[4pt]
\\
\end{aligned}
$$ {#eq-hurdle-model}
Weakly regularising priors were employed for prior sample dataset. These were the default priors in the `brms` package for all intercept terms which are scaled to the expected response value when all predictors are at their means and use a student $t$ distribution with degrees of freedom $\nu=3$, and variance terms similarly scaled with $\mu=0$. The only change to this was to set reasonable upper and lower bounds for the prior condition effects to limit prediction of impossible TUL values. The priors were as follows:

$$
\tiny
\begin{aligned}
& \textbf{Priors (prior sample data model)} \\
\gamma_0 &\sim \text{Logistic}(2, 0.1) & \text{Prior for intercept in hurdle model i.e., Assisted condition} \\
\beta_0 &\sim \text{Student}\ t(3, 3, 13.3) & \text{Prior for intercept in student}\ t\ \text{model i.e., Assisted condition} \\
\gamma_1,\beta_1 &\sim \text{Student}\ t(3, 0, 15, \text{lb}=-60, \text{lb}=60) & \text{Prior for Condition effects in both models i.e., Core minus Assisted condition} \\
\sigma_y,\sigma_{\gamma_{0_{j}}},\sigma_{\gamma_{0_{k}}},\sigma_{\gamma_{0_{l}}},\sigma_{b_{0_{j}}},\sigma_{b_{0_{k}}},\sigma_{b_{0_{l}}} \ &\sim \text{Student}\ t(3, 0, 13.3, \text{lb}=0) & \text{Prior for all variability parameters} \\
\nu_y &\sim \text{Gamma}(2,1) & \text{Prior for student}\ t\ \text{degrees of freedom} \\
\end{aligned}
$$ {#eq-hurdle-prior}

We then took posterior parameter estimates from the prior sample model and used these to generate informative priors for the experimental data models which were as follows:

$$
\tiny
\begin{aligned}
& \textbf{Priors (experimental sample data model)} \\
\gamma_0 &\sim \text{Student}\ t(3.28, -3.03, 0.12) & \text{Prior for intercept in hurdle model i.e., Assisted condition} \\
\beta_0 &\sim \text{Student}\ t(3.28, 2.79, 1.30) & \text{Prior for intercept in student}\ t\ \text{model i.e., Assisted condition} \\
\gamma_1 &\sim \text{Student}\ t(3.28, -0.19, 0.11) & \text{Prior for Condition effects in hurdle model i.e., Core minus Assisted condition} \\
\beta_1 &\sim \text{Student}\ t(3.28, 0.07, 0.58) & \text{Prior for Condition effects in student}\ t\ \text{model i.e., Core minus Assisted condition} \\
\sigma_y &\sim \text{Student}\ t(3, 10.59, 0.19, \text{lb}=0) & \text{Prior for residual variability parameter} \\
\sigma_{\gamma_{0_{j}}} &\sim \text{Student}\ t(3, 0.31, 0.08, \text{lb}=0) & \text{Prior for location variability parameter in hurdle model} \\
\sigma_{\gamma_{0_{k}}} &\sim \text{Student}\ t(3, 1.16, 0.07, \text{lb}=0) & \text{Prior for member variability parameter in hurdle model} \\
\sigma_{\gamma_{0_{l}}} &\sim \text{Student}\ t(3, 0.15, 0.08, \text{lb}=0) & \text{Prior for machine variability parameter in hurdle model} \\
\sigma_{b_{0_{j}}} &\sim \text{Student}\ t(3, 3.43, 0.62, \text{lb}=0) & \text{Prior for location variability parameter in student}\ t\ \text{model} \\
\sigma_{b_{0_{k}}} &\sim \text{Student}\ t(3, 10.2, 0.23, \text{lb}=0) & \text{Prior for member variability parameter in student}\ t\ \text{model} \\
\sigma_{b_{0_{l}}} &\sim \text{Student}\ t(3, 3.72, 0.93, \text{lb}=0) & \text{Prior for machine variability parameter in student}\ t\ \text{model} \\
\nu_y &\sim \text{Gamma}(2,1) & \text{Prior for student}\ t\ \text{degrees of freedom} \\
\end{aligned}
$$ {#eq-hurdle-prior-exp}

### Rating of Perceived Effort and Discomfort Analysis

Despite the use of two different scales and protocols for data collection of perception of effort in our samples i.e., a session RPE using the 6-20 Borg scale for the prior sample and immediately post each exercise RPE using a 0-10 scale, both scales were anchored at their limits as in essence no effort (6 or 0) or maximal effort (20 or 10). As such, and as the intention was to utilise the prior sample data to assist in producing empirical prior distributions for our experimental data models, we opted to rescale both outcomes to lie on the $(0,1)$ interval such that they reflected the percent effort that was reported as perceived [@steeleWhatPerceptionEffort2020]. We then employed an ordered beta regression model [@kubinecOrderedBetaRegression2022] which employs a cutpoint process similar to ordered logistic models in order to model both the continuous responses on the $(0,1)$ interval reflecting some effort though not maximal, and the degenerate response on the bounds $[0,1]$ reflecting both no and maximal effort respectively. We approached the rating of perceived discomfort similarly as this scale was also anchored between no discomfort and the maximum imaginable. 

For both the prior sample and experimental study data the following model was employed which included a fixed (i.e., population level) effect for the session type, Core or Assisted, where Assisted was coded as the intercept. The model also included random (i.e., cluster or group level) effects as intercepts for the location (i.e., the clinic the session was performed at), the member id, and the resistance machine used for the experimental data model only (note, due to the session RPE reported in the prior sample data and that we sampled only one session we do not have member or machine random effects, and due to the cross-over nature of the experimental design the random effects for location, member, and machine were modelled as nested in this dataset). These fixed and random effects were modelled as predictors for both the mean and precision parameters of the ordered beta regression model. As noted, RPE in both datasets was rescaled to lie on the $(0,1)$ interval. Formally the model(s) for $i^{th}$ RPE across condition $c$ within the $j^{th}$ location, $k^{th}$ member, $l^{th}$ machine were as follows (note that the model for the prior dataset omits the random effect for machine):


$$
\tiny
\begin{aligned}
\text{RPE}_{ic} &\sim
\begin{Bmatrix}
0 & \text{with probability } \alpha_{ic_{j[i],k[i],l[i]}} \\[4pt]
\in (0,1) & \text{with probability } \delta_{ic_{j[i],k[i],l[i]}} \\[4pt]
1 & \text{with probability } \gamma_{ic_{j[i],k[i],l[i]}} \\[4pt]
\end{Bmatrix}
\\
\\
\text{logit}(\alpha_{ic}) &= 1-(X'\beta-k_1) & \text{Probability of obtaining a 0} \\[4pt]
\text{logit}(\delta_{ic}) &= \bigr[(X'\beta-k_1) - (X'\beta-k_2)\bigr]\text{Beta}(X'\beta, X'
\beta_\phi) & \text{Probability of obtaining a value between 0 and 1} \\[4pt]
\text{logit}(\gamma_{ic}) &= (X'\beta-k_2) & \text{Probability of obtaining a 1} \\[4pt]
\\
X'\beta&=(\beta_0 + b_{0_{j[i],k[i],l[i]}}) + \beta_1 \text{Condition}_{ic} & \text{Vector of predictors} \\[4pt] 
b_{0_j} &\sim \mathcal{N}(0, \sigma_{b_{0_{j}}}), \text{for location j} = 1,\ ...,\text{J} & \text{Variation in intercepts for location in student}\ t\ \text{model model} \\[4pt]
b_{0_k} &\sim \mathcal{N}(0, \sigma_{b_{0_{k}}}), \text{for member k} = 1,\ ...,\text{K} & \text{Variation in intercepts for member in student}\ t\ \text{model model} \\[4pt]
b_{0_l} &\sim \mathcal{N}(0, \sigma_{b_{0_{l}}}), \text{for machine l} = 1,\ ...,\text{L} & \text{Variation in intercepts for machine  in student}\ t\ \text{model model} \\[4pt]
X'\beta_\phi&=(\beta_{\phi0} + b_{\phi0_{j[i],k[i],l[i]}}) + \beta_{\phi1} \text{Condition}_{ic} & \text{Vector of predictors} \\[4pt] 
b_{\phi0_j} &\sim \mathcal{N}(0, \sigma_{b_{\phi0_{j}}}), \text{for location j} = 1,\ ...,\text{J} & \text{Variation in intercepts for location in student}\ t\ \text{model model} \\[4pt]
b_{\phi0_k} &\sim \mathcal{N}(0, \sigma_{b_{\phi0_{k}}}), \text{for member k} = 1,\ ...,\text{K} & \text{Variation in intercepts for member in student}\ t\ \text{model model} \\[4pt]
b_{\phi0_l} &\sim \mathcal{N}(0, \sigma_{b_{\phi0_{l}}}), \text{for machine l} = 1,\ ...,\text{L} & \text{Variation in intercepts for machine  in student}\ t\ \text{model model} \\[4pt]
\\
\end{aligned}
$$ {#eq-ordbeta-model}

Weakly regularising priors were employed for prior sample dataset. These were the default priors in the `ordbetareg` package for all intercept terms which are scaled to the expected response value when all predictors are at their means and use a student $t$ distribution with degrees of freedom $\nu=3$, and variance terms similarly scaled with $\mu=0$. We left the flat prior on the fixed effect for condition given we were primarily interested in letting the prior dataset speak for itself in generating a posterior distribution to use as prior in the experimental data model. As noted, the prior sample model only included the random effects for location. The priors were as follows:

$$
\tiny
\begin{aligned}
&\textbf{Priors (prior sample data model)} \\
\beta_0 &\sim \text{Student}\ t(3, 0.6, 2.5) & \text{Prior for intercept of mean parameter i.e., Assisted condition} \\
\beta_{\phi0} &\sim \text{Student}\ t(3, 0, 2.5) & \text{Prior for intercept of precision parameter i.e., Assisted condition} \\
\beta_1,\beta_{\phi1} &\sim \text{Uniform}(\text{lb}=-\infty,u=\infty) & \text{Prior for Condition effects in both location and precision parameters i.e., Core minus Assisted condition} \\
\sigma_{b_{0_{j}}},\sigma_{b_{\phi0_{j}}} \ &\sim \text{Student}\ t(3, 0, 2.5, \text{lb}=0) & \text{Prior for location variability parameters} \\
k_1,k_2 &\sim \text{Induced dirichlet}(1,1,1) & \text{Prior for cutpoint probabilities} \\
\end{aligned}
$$ {#eq-ordbeta-prior}

We then took posterior parameter estimates from the prior sample model and used these to generate informative priors for the experimental data model which were as follows:

$$
\tiny
\begin{aligned}
&\textbf{Priors (experimental sample data model)} \\
\beta_0 &\sim \text{Student}\ t(3, 0.35, 0.05) & \text{Prior for intercept of mean parameter i.e., Assisted condition} \\
\beta_{\phi0} &\sim \text{Student}\ t(3, 2.01, 0.07) & \text{Prior for intercept of precision parameter i.e., Assisted condition} \\
\beta_1 &\sim \text{Student}\ t(3, -0.24, 0.04) & \text{Prior for Condition effects in mean parameter i.e., Core minus Assisted condition} \\
\beta_{\phi1} &\sim \text{Student}\ t(3, -0.48, 0.06) & \text{Prior for Condition effects in precision parameter i.e., Core minus Assisted condition} \\
\sigma_{b_{0_{j}}} \ &\sim \text{Student}\ t(3, 0.19, 0.04, \text{lb}=0) & \text{Prior for location variability parameters} \\
\sigma_{b_{\phi0_{j}}} \ &\sim \text{Student}\ t(3, 0.26, 0.05, \text{lb}=0) & \text{Prior for all other variability parameters} \\
\sigma_{b_{0_{k}}},\sigma_{b_{0_{l}}},\sigma_{b_{\phi0_{k}}},\sigma_{b_{\phi0_{l}}} \ &\sim \text{Student}\ t(3, 0, 2.5, \text{lb}=0) & \text{Prior for all variability parameters} \\
k_1,k_2 &\sim \text{Induced dirichlet}(1,1,1) & \text{Prior for cutpoint probabilities} \\
\end{aligned}
$$ {#eq-ordbeta-prior-exp}

We did not have prior sample data for rating of perceived discomfort and so for this outcome we used the same model as above for the RPE outcomes but with wholly default weakly regularising priors.

# Results
In the experimental dataset we ended up with `r nrow(data)/2` observations for each outcome across for each of the two conditions. Our prior sample for TUL after filtering to the same sample of machines came from `r length(unique(prior_data_tul$id))` members (Core = `r length(unique(filter(prior_data_tul, core_assisted == "core")$id))`, Assisted = `r length(unique(filter(prior_data_tul, core_assisted == "assisted")$id))`) from `r length(unique(prior_data_tul$location))` locations encompassing `r nrow(prior_data_tul)` observations. The distributions of raw data from both the prior sample and experimental datasets can be seen in @fig-raw.
```{r}
#| label: fig-raw
#| fig-width: 7.5
#| fig-height: 7
#| fig-cap: The top two panels show the distributions as histograms of both time under load and session rating of perceived effort in the prior sample of data, and the bottom three panels show the paired responses for time under load in addition to the paired responses and histograms for the rating of perceived effort and discomfort in the current experimental data (note, the prescribed target time under load range of 90-120 seconds is indicated by the vertical dashed lines in the top left panel and horizontal dashed lines in the bottom left panel).

targets::tar_load(plot_combined_data)

plot_combined_data

```



## Time Under Load
```{r}
targets::tar_load(model_prior_sample_tul)
targets::tar_load(model_tul)

preds_prior_tul <- avg_predictions(model_prior_sample_tul,
                               variables = "core_assisted",
                               re_formula = NA) |>
  mutate(across(where(is.numeric), round, 2))

preds_tul <- avg_predictions(model_tul,
                               variables = "core_assisted",
                               re_formula = NA) |>
  mutate(across(where(is.numeric), round, 2))

contrast_prior_tul <- avg_comparisons(model_prior_sample_tul,
                               variables = "core_assisted",
                               re_formula = NA) |>
  mutate(across(where(is.numeric), round, 2))

contrast_tul <- avg_comparisons(model_tul,
                               variables = "core_assisted",
                               re_formula = NA) |>
  mutate(across(where(is.numeric), round, 2))

preds_prior_tul_hu <- avg_predictions(model_prior_sample_tul,
                               variables = "core_assisted",
                               re_formula = NA,
                               dpar = "hu") |>
  mutate(across(where(is.numeric), round, 2))

preds_tul_hu <- avg_predictions(model_tul,
                               variables = "core_assisted",
                               re_formula = NA,
                               dpar = "hu") |>
  mutate(across(where(is.numeric), round, 2))

contrast_prior_tul_hu <- avg_comparisons(model_prior_sample_tul,
                               variables = "core_assisted",
                               re_formula = NA,
                               dpar = "hu") |>
  mutate(across(where(is.numeric), round, 2))

contrast_tul_hu <- avg_comparisons(model_tul,
                               variables = "core_assisted",
                               re_formula = NA,
                               dpar = "hu") |>
  mutate(across(where(is.numeric), round, 2))

```
In our prior sample model there was little difference between Core and Assisted sessions in terms of both mean TUL and the probability of stopping at 120 seconds. The estimated TUL for Core sessions was `r preds_prior_tul$estimate[2]+120` [95%QI: `r preds_prior_tul$conf.low[2]+120`, `r preds_prior_tul$conf.high[2]+120`] seconds, for Assisted sessions was `r preds_prior_tul$estimate[1]+120` [95%QI: `r preds_prior_tul$conf.low[1]+120`, `r preds_prior_tul$conf.high[1]+120`] seconds, and the between condition contrast (Core minus Assisted) was `r contrast_prior_tul$estimate` [95%QI: `r contrast_prior_tul$conf.low`, `r contrast_prior_tul$conf.high`] seconds. The probability of stopping at 120 seconds for Core sessions was `r scales::percent(preds_prior_tul_hu$estimate[2])` [95%QI: `r scales::percent(preds_prior_tul_hu$conf.low[2])`, `r scales::percent(preds_prior_tul_hu$conf.high[2])`], for Assisted sessions was `r scales::percent(preds_prior_tul_hu$estimate[1])` [95%QI: `r scales::percent(preds_prior_tul_hu$conf.low[1])`, `r scales::percent(preds_prior_tul_hu$conf.high[1])`], and the between condition contrast (Core minus Assisted) was `r scales::percent(contrast_prior_tul_hu$estimate)` [95%QI: `r scales::percent(contrast_prior_tul_hu$conf.low)`, `r scales::percent(contrast_prior_tul_hu$conf.high)`].

Our experimental sample model showed far greater difference between Core and Assisted sessions in terms of both mean TUL and the probability of stopping at 120 seconds, in addition to the posterior estimates differing considerably from the prior sample estimates in terms of between condition contrasts for TUL and probability of stopping t 120 seconds, Assisted condition TUL, and both conditions probability of stopping at 120 seconds. The estimated TUL for Core sessions was `r preds_tul$estimate[2]+120` [95%QI: `r preds_tul$conf.low[2]+120`, `r preds_tul$conf.high[2]+120`] seconds, for Assisted sessions was `r preds_tul$estimate[1]+120` [95%QI: `r preds_tul$conf.low[1]+120`, `r preds_tul$conf.high[1]+120`] seconds, and the between condition contrast (Core minus Assisted) was `r contrast_tul$estimate` [95%QI: `r contrast_tul$conf.low`, `r contrast_tul$conf.high`] seconds. The probability of stopping at 120 seconds for Core sessions was `r scales::percent(preds_tul_hu$estimate[2])` [95%QI: `r scales::percent(preds_tul_hu$conf.low[2])`, `r scales::percent(preds_tul_hu$conf.high[2])`], for Assisted sessions was `r scales::percent(preds_tul_hu$estimate[1])` [95%QI: `r scales::percent(preds_tul_hu$conf.low[1])`, `r scales::percent(preds_tul_hu$conf.high[1])`], and the between condition contrast (Core minus Assisted) was `r scales::percent(contrast_tul_hu$estimate)` [95%QI: `r scales::percent(contrast_tul_hu$conf.low)`, `r scales::percent(contrast_tul_hu$conf.high)`].

All marginal predictions (i.e., global grand means) for predictions and contrasts can be seen in @fig-tul.

```{r}
#| label: fig-tul
#| fig-width: 7.5
#| fig-height: 7
#| fig-cap: The top two panels show the prior (i.e., generated from the prior sample) and posterior (i.e., the updated distributions after observing the current experimental data) distributions with median (point) and 95% quantile intervals (error bar) of time under load (note, the prescribed target time under load range of 90-120 seconds is indicated by the vertical dashed lines in the top left panel) and the bottom panels show the probabilities of stopping at 120 seconds.

targets::tar_load(plot_combined_tul)

plot_combined_tul

```


## Rating of Perceived Effort and Discomfort
```{r}
targets::tar_load(model_prior_sample_rpe)
targets::tar_load(model_rpe)
targets::tar_load(model_prior_sample_discomfort)
targets::tar_load(model_discomfort)

preds_prior_rpe <- avg_predictions(model_prior_sample_rpe,
                               variables = "core_assisted",
                               re_formula = NA) |>
  mutate(across(where(is.numeric), round, 2))

preds_rpe <- avg_predictions(model_rpe,
                               variables = "core_assisted",
                               re_formula = NA) |>
  mutate(across(where(is.numeric), round, 2))

contrast_prior_rpe <- avg_comparisons(model_prior_sample_rpe,
                               variables = "core_assisted",
                               re_formula = NA) |>
  mutate(across(where(is.numeric), round, 2))

contrast_rpe <- avg_comparisons(model_rpe,
                               variables = "core_assisted",
                               re_formula = NA) |>
  mutate(across(where(is.numeric), round, 2))

preds_prior_rpe_phi <- avg_predictions(model_prior_sample_rpe,
                               variables = "core_assisted",
                               re_formula = NA,
                               dpar = "phi",
                               type = "link") |>
  mutate(across(where(is.numeric), round, 2))

contrast_prior_rpe_phi <- avg_comparisons(model_prior_sample_rpe,
                               variables = "core_assisted",
                               re_formula = NA,
                               dpar = "phi",
                               type = "link") |>
  mutate(across(where(is.numeric), round, 2))

preds_rpe_phi <- avg_predictions(model_rpe,
                               variables = "core_assisted",
                               re_formula = NA,
                             dpar = "phi",
                               type = "link") |>
  mutate(across(where(is.numeric), round, 2))

contrast_rpe_phi <- avg_comparisons(model_rpe,
                               variables = "core_assisted",
                               re_formula = NA,
                             dpar = "phi",
                               type = "link") |>
  mutate(across(where(is.numeric), round, 2))

preds_discomfort <- avg_predictions(model_discomfort,
                               variables = "core_assisted",
                               re_formula = NA) |>
  mutate(across(where(is.numeric), round, 2))

contrast_discomfort <- avg_comparisons(model_discomfort,
                               variables = "core_assisted",
                               re_formula = NA) |>
  mutate(across(where(is.numeric), round, 2))

preds_discomfort_phi <- avg_predictions(model_discomfort,
                               variables = "core_assisted",
                               re_formula = NA,
                             dpar = "phi",
                               type = "link") |>
  mutate(across(where(is.numeric), round, 2))

contrast_discomfort_phi <- avg_comparisons(model_discomfort,
                               variables = "core_assisted",
                               re_formula = NA,
                             dpar = "phi",
                               type = "link") |>
  mutate(across(where(is.numeric), round, 2))

```
In our prior sample model there was a small difference between Core and Assisted sessions in RPE. The estimated RPE as a percentage for Core sessions was `r scales::percent(preds_prior_rpe$estimate[2])` [95%QI: `r scales::percent(preds_prior_rpe$conf.low[2])`, `r scales::percent(preds_prior_rpe$conf.high[2])`], for Assisted sessions `r scales::percent(preds_prior_rpe$estimate[1])` [95%QI: `r scales::percent(preds_prior_rpe$conf.low[1])`, `r scales::percent(preds_prior_rpe$conf.high[1])`], and the between condition contrast (Core minus Assisted) was `r scales::percent(contrast_prior_rpe$estimate)` [95%QI: `r scales::percent(contrast_prior_rpe$conf.low)`, `r scales::percent(contrast_prior_rpe$conf.high)`]. The $\phi$ parameter for precision of the beta distribution was higher in the Assisted condition suggesting that RPE reported was more clustered around the estimated RPE values as compared to in the Core condition. The $\phi$ parameter for Core sessions was `r preds_prior_rpe_phi$estimate[2]` [95%QI: `r preds_prior_rpe_phi$conf.low[2]`, `r preds_prior_rpe_phi$conf.high[2]`], for Assisted sessions `r preds_prior_rpe_phi$estimate[1]` [95%QI: `r preds_prior_rpe_phi$conf.low[1]`, `r preds_prior_rpe_phi$conf.high[1]`], and the between condition contrast (Core minus Assisted) was `r contrast_prior_rpe_phi$estimate` [95%QI: `r contrast_prior_rpe_phi$conf.low`, `r contrast_prior_rpe_phi$conf.high`].

Our experimental sample model showed a similar magnitude of difference between Core and Assisted sessions in RPE, though the posterior estimates for RPEs were considerably greater compared with the prior sample estimates. The estimated RPE as a percentage for Core sessions was `r scales::percent(preds_rpe$estimate[2])` [95%QI: `r scales::percent(preds_rpe$conf.low[2])`, `r scales::percent(preds_rpe$conf.high[2])`], for Assisted sessions `r scales::percent(preds_rpe$estimate[1])` [95%QI: `r scales::percent(preds_rpe$conf.low[1])`, `r scales::percent(preds_rpe$conf.high[1])`], and the between condition contrast (Core minus Assisted) was `r scales::percent(contrast_rpe$estimate)` [95%QI: `r scales::percent(contrast_rpe$conf.low)`, `r scales::percent(contrast_rpe$conf.high)`]. Similarly to the prior data, the $\phi$ parameter for precision of the beta distribution in our experimental sample was higher in the Assisted condition suggesting that RPE reported was more clustered around the estimated RPE values as compared to in the Core condition. The $\phi$ parameter for Core sessions was `r preds_rpe_phi$estimate[2]` [95%QI: `r preds_rpe_phi$conf.low[2]`, `r preds_rpe_phi$conf.high[2]`], for Assisted sessions `r preds_rpe_phi$estimate[1]` [95%QI: `r preds_rpe_phi$conf.low[1]`, `r preds_rpe_phi$conf.high[1]`], and the between condition contrast (Core minus Assisted) was `r contrast_rpe_phi$estimate` [95%QI: `r contrast_rpe_phi$conf.low`, `r contrast_rpe_phi$conf.high`].

The rating of perceived discomfort results showed a similar pattern to the RPE albeit with a slightly larger magnitude of difference between conditions. The estimated rating of perceived discomfort as a percentage for Core sessions was `r preds_discomfort$estimate[2]*10` [95%QI: `r preds_discomfort$conf.low[2]*10`, `r preds_discomfort$conf.high[2]*10`], for Assisted sessions `r preds_discomfort$estimate[1]*10` [95%QI: `r preds_discomfort$conf.low[1]*10`, `r preds_discomfort$conf.high[1]*10`], and the between condition contrast (Core minus Assisted) was `r contrast_discomfort$estimate*10` [95%QI: `r contrast_discomfort$conf.low*10`, `r contrast_discomfort$conf.high*10`]. The $\phi$ parameter for precision of the beta distribution was higher in the Core condition suggesting that rating of perceived discomfort reported was more clustered around the estimated rating of perceived discomfort values as compared to in the Assisted condition, though the contrast for this was less precise than in the RPE models. The $\phi$ parameter for Core sessions was `r preds_prior_rpe_phi$estimate[2]` [95%QI: `r preds_prior_rpe_phi$conf.low[2]`, `r preds_prior_rpe_phi$conf.high[2]`], for Assisted sessions `r preds_prior_rpe_phi$estimate[1]` [95%QI: `r preds_prior_rpe_phi$conf.low[1]`, `r preds_prior_rpe_phi$conf.high[1]`], and the between condition contrast (Core minus Assisted) was `r contrast_prior_rpe_phi$estimate` [95%QI: `r contrast_prior_rpe_phi$conf.low`, `r contrast_prior_rpe_phi$conf.high`].

All marginal predictions (i.e., global grand means) for predictions and contrasts can be seen in @fig-rpe.

```{r}
#| label: fig-rpe
#| fig-width: 7.5
#| fig-height: 7
#| fig-cap: The top two panels show the prior (i.e., generated from the prior sample) and posterior (i.e., the updated distributions after observing the current experimental data) distributions with median (point) and 95% quantile intervals (error bar) of rating of perceived effort on the percentage scale, and the bottom panels show posterior disributions only for rating of perceived discomfort transformed back to the arbitrary unit scale (0,10).

targets::tar_load(plot_combined_rpe_discomfort)

plot_combined_rpe_discomfort

```

# Discussion
Our study is a first to offer insights into the role of supervision (i.e., Core vs Assisted sessions) during RT both *in situ* in an ecologically valid real world setting in addition to during an experimental study. Under standardised training protocol prescription (i.e., single sets of RT using resistance machines to momentary failure using a fixed repetition duration using a load that should permit momentary failure in a target TUL range of 90-120 seconds) we examined exercise performance as the TUL, in addition to RPE and rating of perceived discomfort. Our key findings were that under real world settings in our prior sample there did not appear to be a difference in TUL between Core and Assisted sessions nor the probability of whether members targeted the upper bound of the prescribed TUL range (i.e., 120s), yet in our experimental study there was a clear benefit to TUL performance when under supervision and reduction in the probability of targeting the upper prescribed TUL range. There was a small difference in RPE reported with and without supervision under both real world and experimental conditions with members reporting higher RPE in Assisted training conditions, though RPE on the percentage points scale was notably higher during the experimental study compared with the prior sample for both Core and Assisted sessions. Lastly, rating of perceived discomfort was also higher in the experimental study under supervised Assisted sessions compared to Core sessions. These results in general support prior work highlighting the importance of supervision during RT [@fisherRoleSupervisionResistance2022a; @fisherSupervisionResistanceTraining2023; @carlsonMaleFemalePerceptions2024] and that under unsupervised, and perhaps more so during real world conditions, trainees likely train with suboptimal effort.

We will first discuss the findings from the prior sample of Core and Assisted members. In this *in situ* dataset we find for both Core and Assisted members there is clear evidence of targeting a specific TUL based on the prescribed TUL range of 90-120 seconds. For Core members this is perhaps unsurprising given that, in repetition count based RT prescription, when given the opportunity to self-select repetition number people tend to target ~10 repetitions regardless of the load they self-select and that also most RT prescriptions tend to emphasise that particular target [@steeleAreTraineesLifting2022]. Thus, that members are also shooting for targets under this slightly different type of RT protocol suggests that this might be characteristic of most people training under real world unsupervised conditions. It is however surprising that this is also the case for Assisted members and that TUL differs very little between Core and Assisted sessions. However, the lack of difference in TUL itself is not necessarily indicative of suboptimal training effort, and we did observe slightly higher reported RPE during Assisted training sessions compared to Core sessions. Thus it might be that during Assisted sessions trainees might be more likely to use loads more appropriate for the prescribed TUL range and thus train with closer proximity to failure as compared to under Core sessions in addition to greater clustering of RPE around higher values (indicated by the $\phi$ parameter in the ordered beta regression). This may be due to load progression protocols being more closely followed by supervising exercise scientists as compared to those training unsupervised where, unless using initially heavy loads or in previously well trained persons, most unsupervised trainees do not progress load sufficiently [@steeleAreTraineesLifting2022; @fisherRoleSupervisionResistance2022a]. In future work we plan to explore differences longitudinally in load progression between Core and Assisted members. But, despite the greater RPE reported under Assisted sessions, in percentage points RPE under both Core and Assisted sessions was considerably lower in our prior sample (Core = `r scales::percent(preds_prior_rpe$estimate[2])` [95%QI: `r scales::percent(preds_prior_rpe$conf.low[2])`, `r scales::percent(preds_prior_rpe$conf.high[2])`], Assisted = `r scales::percent(preds_prior_rpe$estimate[1])` [95%QI: `r scales::percent(preds_prior_rpe$conf.low[1])`, `r scales::percent(preds_prior_rpe$conf.high[1])`]) compared with our experimental study (Core = `r scales::percent(preds_rpe$estimate[2])` [95%QI: `r scales::percent(preds_rpe$conf.low[2])`, `r scales::percent(preds_rpe$conf.high[2])`], Assisted = `r scales::percent(preds_rpe$estimate[1])` [95%QI: `r scales::percent(preds_rpe$conf.low[1])`, `r scales::percent(preds_rpe$conf.high[1])`]) suggesting that members in these real world conditions may not be training with sufficient effort and many perhaps "going through the motions" [@steeleHigherEffortbasedParadigm2017].

In contrast to the prior sample, our experimental study clearly showed a benefit to TUL performance with supervision suggesting that it might enhance trainee effort. Further, given we recruited existing Core members and had them use their current training loads, it also reinforces that members may be typically selecting loads that are too light and also training with considerable distance from momentary failure. Though the prescribed protocol *in situ* in the Kieser Australia clinics is for trainees to perform each exercise to momentary failure, despite the average TUL under Core conditions being similar between prior sample and experimental sample (see @fig-tul), we can see in @fig-raw that many were capable of achieving very long TUL before reaching momentary failure in both the Core and Assisted sessions. Interestingly whilst the probability of targeting the 120 second threshold was similar in the prior sample between session types, in the experimental study this was far greater in the Core session condition. We speculate that it might be a result of many members, whom were typically not achieving the 120 second TUL upper threshold in their prior sessions, interpreting our explicit instructions in the study to continue to momentary failure as being to ensure that they continue to this point. Whereas the wide range of TULs, and particularly some of the very high ones, might suggest that others more literally interpreted the instruction to continue to momentary failure. That under the explicit experimental study instructions to train to momentary failure members were likely to train with a greater effort under both conditions is reinforced by the greater RPE in percentage points compared to that reported in the prior sample. In addition to greater average RPE in both conditions, there was also greater clustering of RPE reported under the Assisted condition suggesting that members might have achieved closer proximity to failure whilst supervised. It was also the case that ratings of perceived discomfort were higher under supervision which, as previous evidence has suggested increases with greater proximity to failure [@refaloImprovedUnderstandingProximitytofailure2022a; @refaloInfluenceResistanceTraining2023], also supports that members trained with greater effort whilst supervised. 

The limitations of the present results and conclusions should be noted. Firstly, the lack of difference in our prior sample of members regarding TUL does not necessarily indicate that even during Assisted training sessions members are training sub-optimally as this is a comparison unadjusted for other factors causal of the TUL during training (member characteristics, load used and load progression). However, the session RPE data does perhaps corroborate the inference that, whilst training with slightly greater effort during Assisted training, members *in situ* may still be training with suboptimal effort compared to what occurs under experimental study conditions when explicitly the instruction to train to momentary failure is reinforced. But, a further issue with this is that in that two separate tools/protocols for capturing RPE was used in the prior sample (session RPE with and adapted Borg 6-20 scale) vs the experimental study (scales taken from  Steele et al. [-@steeleDifferentiationPerceivedEffort2017]). The adaptation to the session RPE scale in particular involved changes to verbal anchors and it was noticed in the raw distribution of data (see @fig-raw) that there was an abundance of values of 13 reported. Whether or not the tendency for lower RPE in percentage points in the prior sample is necessarily caused by reporting behaviours due to scale construction or due to members actually training with lower effort *in situ* is not clear. It is planned that for future member data collection we will move towards an exercise by exercise approach using the Steele et al. [-@steeleDifferentiationPerceivedEffort2017] scales. The similar degree of contrast between Core and Assisted conditions in both prior sample and experimental study data though does reinforce the role of supervision in influencing trainee effort. Lastly, despite the impact of supervision on trainee effort, it is still relatively unclear the extent to which it influences adaptation to training. As noted, Robinson et al. [-@robinsonExploringDoseResponse2024] suggest that higher effort through load and/or proximity to failure is important for outcomes and  Fisher et al. [-@fisherRoleSupervisionResistance2022a] reported a moderate standardised mean effect in favour of supervision for strength adaptation (0.40 \[95%CI: 0.06, 0.74\]) but estimates of these effects are still relatively imprecise. Kieser Australia also collect isometric strength test data from their members and so in future work we intend to explore this longitudinally and generate causal estimates regarding the role of supervision during RT from a large sample of members.

# Conclusions
To our knowledge this study is the first examine the role of supervision during RT both *in situ* in an ecologically valid real world setting in addition to during an experimental study. Under real world settings there was little difference in exercise performance, yet in our experimental study there was a clear benefit to performance when under supervision. There was a small difference in rating of perceived effort reported with and without supervision under both real world and experimental conditions suggesting a that under supervision trainees train with greater proximity to failure, which was also supported by greater rating of perceived discomfort under supervision. These results in general support prior work highlighting the importance of supervision during RT and that under unsupervised, and perhaps more so during real world conditions, trainees likely train with suboptimal effort.


      JAMES TO UPDATE THESE SECTIONS!!!!! BUT FEEL FREE TO ADD ANYTHING YOU THINK APPROPRIATE

# Contributions

Authors should report the contributions of each author in the a specific contribution section based on the guidelines set forth by the International Committee of Medical Journal Editors.

Please indicate author contributions as clearly as possible, according to the following criteria:

-   Substantial contributions to conception and design
-   Acquisition of data
-   Analysis and interpretation of data
-   Drafting the article or revising it critically for important intellectual content
-   Final approval of the version to be published

# Acknowledgements

People who contributed to the work but do not fit our author criteria should be listed in the acknowledgements, along with their contributions. You must ensure that anyone named in the acknowledgements agrees to being so named.

Funding sources should not be included in the acknowledgements, but in the section below.

# Funding Information

Please provide a list of the sources of funding, as well as the relevant grant numbers, where possible. List the authors associated with specific funding sources. You will also enter this information in a form during the submission process, but it must be repeated here.

# Data and Supplementary Material Accessibility

This should list the database(s) and, if appropriate, the respective accession numbers and DOIs for all data or supplementary material for the manuscript that has been made publicly available on a trusted digital repository. If no data, code, or supplementary material are available for this manuscript then the reason for this should be explained here.
